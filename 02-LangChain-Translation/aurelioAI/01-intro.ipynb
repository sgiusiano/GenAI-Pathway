{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8de488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/santiagoarielgiusiano/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages (1.55.0)\n",
      "Collecting openai\n",
      "  Downloading openai-1.98.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/santiagoarielgiusiano/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/santiagoarielgiusiano/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/santiagoarielgiusiano/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/santiagoarielgiusiano/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages (from openai) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/santiagoarielgiusiano/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages (from openai) (2.10.1)\n",
      "Requirement already satisfied: sniffio in /Users/santiagoarielgiusiano/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/santiagoarielgiusiano/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/santiagoarielgiusiano/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/santiagoarielgiusiano/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/santiagoarielgiusiano/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /Users/santiagoarielgiusiano/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/santiagoarielgiusiano/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/santiagoarielgiusiano/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/santiagoarielgiusiano/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/santiagoarielgiusiano/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Downloading openai-1.98.0-py3-none-any.whl (767 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.7/767.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.55.0\n",
      "    Uninstalling openai-1.55.0:\n",
      "      Successfully uninstalled openai-1.55.0\n",
      "Successfully installed openai-1.98.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install \\\n",
    "#    langchain-core \\\n",
    "#    langchain-openai \\\n",
    "#    langchain-community\n",
    "#!pip install scikit-image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b12f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import langchain\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6538f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_model = 'gpt-4o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffad2317",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For normal accurate responses\n",
    "llm = ChatOpenAI(temperature=0, model=openai_model)\n",
    "\n",
    "# For unique creative responses\n",
    "creative_llm = ChatOpenAI(temperature=1, model=openai_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55603af",
   "metadata": {},
   "source": [
    "We will take an article draft and use LangChain to generate various useful items around this article. We'll be creating:\n",
    "\n",
    "- An article title.\n",
    "- An article description.\n",
    "- Structured output to get feedback on our article similar to what we might get from a human editor.\n",
    "- A thumbnail/hero image for our article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fdcda33",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "We believe AI's short—to mid-term future belongs to agents and that the long-term future\n",
    "of *AGI* may evolve from agentic systems. Our definition of agents covers any\n",
    "neuro-symbolic system in which we merge neural AI (such as an LLM) with semi-traditional\n",
    "software.\n",
    "\n",
    "With agents, we allow LLMs to integrate with code — allowing AI to search the web,\n",
    "perform math, and essentially integrate into anything we can build with code. It should\n",
    "be clear the scope of use cases is phenomenal where AI can integrate with the broader\n",
    "world of software.\n",
    "\n",
    "In this introduction to AI agents, we will cover the essential concepts that make them\n",
    "what they are and why that will make them the core of real-world AI in the years to\n",
    "come.\n",
    "\n",
    "---\n",
    "\n",
    "## Neuro-Symbolic Systems\n",
    "\n",
    "Neuro-symbolic systems consist of both neural and symbolic computation, where:\n",
    "\n",
    "- Neural refers to LLMs, embedding models, or other neural network-based models.\n",
    "- Symbolic refers to logic containing symbolic logic, such as code.\n",
    "\n",
    "Both neural and symbolic AI originate from the early philosophical approaches to AI:\n",
    "connectionism (now neural) and symbolism. Symbolic AI is the more traditional AI.\n",
    "Diehard symbolists believed they could achieve true AGI via written rules, ontologies,\n",
    "and other logical functions.\n",
    "\n",
    "The other camp were the connectionists. Connectionism emerged in 1943 with a theoretical\n",
    "neural circuit but truly kicked off with Rosenblatt's perceptron paper in 1958 [1][2].\n",
    "Both of these approaches to AI are fascinating but deserve more time than we can give\n",
    "them here, so we will leave further exploration of these concepts for a future chapter.\n",
    "\n",
    "Most important to us is understanding where symbolic logic outperforms neural-based\n",
    "compute and vice-versa.\n",
    "\n",
    "| Neural | Symbolic |\n",
    "| --- | --- |\n",
    "| Flexible, learned logic that can cover a huge range of potential scenarios. | Mostly hand-written rules which can be very granular and fine-tuned but hard to scale. |\n",
    "| Hard to interpret why a neural system does what it does. Very difficult or even impossible to predict behavior. | Rules are written and can be understood. When unsure why a particular ouput was produced we can look at the rules / logic to understand. |\n",
    "| Requires huge amount of data and compute to train state-of-the-art neural models, making it hard to add new abilities or update with new information. | Code is relatively cheap to write, it can be updated with new features easily, and latest information can often be added often instantaneously. |\n",
    "| When trained on broad datasets can often lack performance when exposed to unique scenarios that are not well represented in the training data. | Easily customized to unique scenarios. |\n",
    "| Struggles with complex computations such as mathematical operations. | Perform complex computations very quickly and accurately. |\n",
    "\n",
    "Pure neural architectures struggle with many seemingly simple tasks. For example, an LLM\n",
    "*cannot* provide an accurate answer if we ask it for today's date.\n",
    "\n",
    "Retrieval Augmented Generation (RAG) is commonly used to provide LLMs with up-to-date\n",
    "knowledge on a particular subject or access to proprietary knowledge.\n",
    "\n",
    "### Giving LLMs Superpowers\n",
    "\n",
    "By 2020, it was becoming clear that neural AI systems could not perform tasks symbolic\n",
    "systems typically excelled in, such as arithmetic, accessing structured DB data, or\n",
    "making API calls. These tasks require discrete input parameters that allow us to process\n",
    "them reliably according to strict written logic.\n",
    "\n",
    "In 2022, researchers at AI21 developed Jurassic-X, an LLM-based \"neuro-symbolic\n",
    "architecture.\" Neuro-symbolic refers to merging the \"neural computation\" of large\n",
    "language models (LLMs) with more traditional (i.e. symbolic) computation of code.\n",
    "\n",
    "Jurassic-X used the Modular Reasoning, Knowledge, and Language (MRKL) system [3]. The\n",
    "researchers developed MRKL to solve the limitations of LLMs, namely:\n",
    "\n",
    "- Lack of up-to-date knowledge, whether that is the latest in AI or something as simple\n",
    "as today's date.\n",
    "- Lack of proprietary knowledge, such as internal company docs or your calendar\n",
    "bookings.\n",
    "- Lack of reasoning, i.e. the inability to perform operations that traditional software\n",
    "is good at, like running complex mathematical operations.\n",
    "- Lack of ability to generalize. Back in 2022, most LLMs had to be fine-tuned to perform\n",
    "well in a specific domain. This problem is still present today but far less prominent as\n",
    "the SotA models generalize much better and, in the case of MRKL, are able to use tools\n",
    "relatively well (although we could certainly take the MRKL solution to improve tool use\n",
    "performance even today).\n",
    "\n",
    "MRKL represents one of the earliest forms of what we would now call an agent; it is an\n",
    "LLM (neural computation) paired with executable code (symbolic computation).\n",
    "\n",
    "## ReAct and Tools\n",
    "\n",
    "There is a misconception in the broader industry that an AI agent is an LLM contained\n",
    "within some looping logic that can generate inputs for and execute code functions. This\n",
    "definition of agents originates from the huge popularity of the ReAct agent framework\n",
    "and the adoption of a similar structure with function/tool calling by LLM providers such\n",
    "as OpenAI, Anthropic, and Ollama.\n",
    "\n",
    "![ReAct agent flow with the Reasoning-Action loop [4]. When the action chosen specifies\n",
    "to use a normal tool, the tool is used and the observation returned for another\n",
    "iteration through the Reasoning-Action loop. To return a final answer to the user the\n",
    "LLM must choose action \"answer\" and provide the natural language response, finishing\n",
    "the loop.](/images/posts/ai-agents/ai-agents-00.png)\n",
    "\n",
    "<small>ReAct agent flow with the Reasoning-Action loop [4]. When the action chosen\n",
    "specifies to use a normal tool, the tool is used and the observation returned for\n",
    "another iteration through the Reasoning-Action loop. To return a final answer to the\n",
    "user the LLM must choose action \"answer\" and provide the natural language response,\n",
    "finishing the loop.</small>\n",
    "\n",
    "Our \"neuro-symbolic\" definition is much broader but certainly does include ReAct agents\n",
    "and LLMs paired with tools. This agent type is the most common for now, so it's worth\n",
    "understanding the basic concept behind it.\n",
    "\n",
    "The **Re**ason **Act**ion (ReAct) method encourages LLMs to generate iterative\n",
    "*reasoning* and *action* steps. During *reasoning,* the LLM describes what steps are to\n",
    "be taken to answer the user's query. Then, the LLM generates an *action,* which we parse\n",
    "into an input to some executable code, which we typically describe as a tool/function\n",
    "call.\n",
    "\n",
    "![ReAct method. Each iteration includes a Reasoning step followed by an Action (tool\n",
    "call) step. The Observation is the output from the previous tool call. During the final\n",
    "iteration the agent calls the answer tool, meaning we generate the final answer for the\n",
    "user.](/images/posts/ai-agents/ai-agents-01.png)\n",
    "\n",
    "<small>ReAct method. Each iteration includes a Reasoning step followed by an Action\n",
    "(tool call) step. The Observation is the output from the previous tool call. During the\n",
    "final iteration the agent calls the answer tool, meaning we generate the final answer\n",
    "for the user.</small>\n",
    "\n",
    "Following the reason and action steps, our action tool call returns an observation. The\n",
    "logic returns the observation to the LLM, which is then used to generate subsequent\n",
    "reasoning and action steps.\n",
    "\n",
    "The ReAct loop continues until the LLM has enough information to answer the original\n",
    "input. Once the LLM reaches this state, it calls a special *answer* action with the\n",
    "generated answer for the user.\n",
    "\n",
    "## Not only LLMs and Tool Calls\n",
    "\n",
    "LLMs paired with tool calling are powerful but far from the only approach to building\n",
    "agents. Using the definition of neuro-symbolic, we cover architectures such as:\n",
    "\n",
    "- Multi-agent workflows that involve multiple LLM-tool (or other agent structure)\n",
    "combinations.\n",
    "- More deterministic workflows where we may have set neural model-tool paths that may\n",
    "fork or merge as the use case requires.\n",
    "- Embedding models that can detect user intents and decide tool-use or LLM\n",
    "selection-based selection in vector space.\n",
    "\n",
    "These are just a few high-level examples of alternative agent structures. Far from being\n",
    "designed for niche use cases, we find these alternative options to frequently perform\n",
    "better than the more common ReAct or Tool agents. We will cover all of these examples\n",
    "and more in future chapters.\n",
    "\n",
    "---\n",
    "\n",
    "Agents are fundamental to the future of AI, but that doesn't mean we should expect that\n",
    "future to come from agents in their most popular form today. ReAct and Tool agents are\n",
    "great and handle many simple use cases well, but the scope of agents is much broader,\n",
    "and we believe thinking beyond ReAct and Tools is key to building future AI.\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "[1] The curious case of Connectionism (2019) [https://www.degruyter.com/document/doi/10.1515/opphil-2019-0018/html](https://www.degruyter.com/document/doi/10.1515/opphil-2019-0018/html)\n",
    "\n",
    "[2] F. Rosenblatt, [The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain](https://www.ling.upenn.edu/courses/cogs501/Rosenblatt1958.pdf) (1958), Psychological Review\n",
    "\n",
    "[3] E. Karpas et al. [MRKL Systems: A Modular, Neuro-Symbolic Architecture That Combines Large Language Models, External Knowledge Sources and Discrete Reasoning](https://arxiv.org/abs/2205.00445) (2022), AI21 Labs\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85c2c6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee803f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI assistant called {name} that helps generate article titles.\"\n",
    ")\n",
    "\n",
    "user_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"You are tasked with creatin a name for a article.\n",
    "The article is here for you to examine:\n",
    "\n",
    "{article}\n",
    "\n",
    "The name should be based of the context of the article.\n",
    "Be creative, but make sure the names are clear, catchy,\n",
    "and relevant to the theme of the article.\n",
    "\n",
    "Only output the article name, no other explanation or\n",
    "text can be provided.\n",
    "\"\"\",\n",
    "    input_variables=[\"article\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25f7de97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are tasked with creatin a name for a article.\n",
      "The article is here for you to examine:\n",
      "\n",
      "TEST\n",
      "\n",
      "The name should be based of the context of the article.\n",
      "Be creative, but make sure the names are clear, catchy,\n",
      "and relevant to the theme of the article.\n",
      "\n",
      "Only output the article name, no other explanation or\n",
      "text can be provided.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt.format(article='TEST').content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "645bef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_messages([system_prompt, user_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c687559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'System: You are an AI assistant that helps generate article titles.\\nHuman: You are tasked with creatin a name for a article.\\nThe article is here for you to examine:\\n\\nTEST STRING\\n\\nThe name should be based of the context of the article.\\nBe creative, but make sure the names are clear, catchy,\\nand relevant to the theme of the article.\\n\\nOnly output the article name, no other explanation or\\ntext can be provided.\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_prompt.format(article=\"TEST STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "066ed45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_one = (\n",
    "    {\n",
    "        \"article\": lambda x: x[\"article\"],\n",
    "        \"name\": lambda x: x[\"name\"]\n",
    "    }\n",
    "    | first_prompt\n",
    "    | creative_llm\n",
    "    | {\"article_title\": lambda x: x.content}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ebc8ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_title': '\"Agents of the Future: Unlocking AI\\'s Potential with Neuro-Symbolic Synergy\"'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_title_msg = chain_one.invoke(\n",
    "    {\n",
    "        \"article\": article,\n",
    "        \"name\": \"Joe\"\n",
    "    }\n",
    ")\n",
    "article_title_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b081d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI assistant that helps build good articles.\"\n",
    ")\n",
    "\n",
    "second_user_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\" You're tasked with creating a description for \n",
    "        the article. The article is here for you to examine:\n",
    "\n",
    "    ---\n",
    "\n",
    "    {article}\n",
    "\n",
    "    ---\n",
    "\n",
    "    Here is the article title '{article_title}'.\n",
    "\n",
    "    Output the SEO friendly article description. Do not output\n",
    "    anything other than the description.\n",
    "    \"\"\",\n",
    "    input_variables=[\"article\", \"article_title\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "157935e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_prompt, second_user_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8d9bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_two = (\n",
    "    {\n",
    "        \"article\": lambda x: x[\"article\"],\n",
    "        \"article_title\": lambda x: x[\"article_title\"]\n",
    "    }\n",
    "    | second_prompt\n",
    "    | llm\n",
    "    | {\"summary\": lambda x: x.content}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e37f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_description = chain_two.invoke({\n",
    "    \"article\": article,\n",
    "    \"article_title\": article_title_msg\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a25feb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'Explore the transformative potential of AI agents in \"Agents of the Future: Unlocking AI\\'s Potential with Neuro-Symbolic Synergy.\" This article delves into the integration of neural AI and symbolic computation, highlighting how these neuro-symbolic systems are set to revolutionize the AI landscape. Discover the capabilities of AI agents, from enhancing LLMs with code to performing complex tasks, and learn why they are poised to become the cornerstone of real-world AI applications. Uncover the future of AI beyond traditional ReAct and Tool agents, and understand the broader scope of agentic systems in shaping the path to AGI.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39fe50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_user_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"You are tasked with creating a new paragraph for the\n",
    "article. The article is here for you to examine:\n",
    "\n",
    "---\n",
    "\n",
    "{article}\n",
    "\n",
    "---\n",
    "\n",
    "Choose one paragraph to review and edit. During your edit,\n",
    "ensure you provide constructive feedback to the user so they\n",
    "can learn where to improve their own writing.\"\"\",\n",
    "    input_variables=[\"article\"]\n",
    ")\n",
    "\n",
    "# prompt template 3: creating a new paragraph for the article\n",
    "third_prompt = ChatPromptTemplate.from_messages([\n",
    " system_prompt,\n",
    " third_user_prompt\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a8ca197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Paragraph(BaseModel):\n",
    "    original_paragraph: str = Field(description=\"The original paragraph\")\n",
    "    edited_paragraph: str = Field(description=\" The improved edited paragraph\")\n",
    "    feedback: str = Field(description=(\n",
    "        \"Constructive feedback on the original paragraph\"\n",
    "    ))\n",
    "\n",
    "structured_llm = creative_llm.with_structured_output(Paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "331907d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_tree = (\n",
    "    {\"article\": lambda x: x['article']}\n",
    "    | third_prompt\n",
    "    | structured_llm\n",
    "    | {\n",
    "        \"original_paragraph\": lambda x: x['original_paragraph'],\n",
    "        \"edited_paragraph\": lambda x: x['edited_paragraph'],\n",
    "        \"feedback\": lambda x: x['feedback']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "22624ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = chain_tree.invoke({\"article\": article})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28ed0c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_paragraph': 'ReAct and Tools agents are great and handle many simple use cases well, but the scope of agents is much broader, and we believe thinking beyond ReAct and Tools is key to building future AI.',\n",
       " 'edited_paragraph': \"ReAct and Tool agents are effective in managing many basic use cases, yet the potential of AI agents extends far beyond these frameworks. To truly advance AI development, it's essential to envision and design agent models that surpass the traditional ReAct and Tool structures.\",\n",
       " 'feedback': \"The original paragraph clearly voices an opinion but lacks depth and clarity. In the revision, I've tried to expand the reasoning behind why moving beyond ReAct and Tool agents is crucial. The phrase 'handle many simple use cases well' was expanded upon to highlight their initial effectiveness, while ensuring the potential beyond them is emphasized. Additionally, the sentence structure was adjusted for better flow and the terms 'ReAct and Tool agents' were made consistent for clarity.\"}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8916f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "image_prompt = PromptTemplate(\n",
    "    input_variables=['article'],\n",
    "    template=(\n",
    "        \"\"\"Generate a prompt wth less than 500 characters to generate an image\n",
    "        based on the following article:\n",
    "\n",
    "        {article}\n",
    "        \"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a56a1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def generate_and_display_image(image_prompt):\n",
    "    print(image_prompt)\n",
    "    image_url = DallEAPIWrapper().run(\n",
    "        image_prompt\n",
    "    )\n",
    "    image_data = io.imread(image_url)\n",
    "\n",
    "    # And update the display code to:\n",
    "    plt.imshow(image_data)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# We wrap this in a runnableLambda for use with LCEL\n",
    "image_gen_runnable = RunnableLambda(generate_and_display_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ed64dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_four= (\n",
    "    {'article': lambda x: x['article']}\n",
    "    | image_prompt\n",
    "    | llm\n",
    "    | (lambda x: x.content)\n",
    "    | image_gen_runnable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5e28adb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an image that visually represents the concept of AI agents as described in the article. The image should depict a futuristic scene where neural AI (represented by a glowing neural network) seamlessly integrates with symbolic AI (depicted as lines of code and logic gates). Show these elements interacting with various digital tools, like a web browser, calculator, and database, symbolizing the AI's ability to perform diverse tasks. Include a central figure, an AI agent, orchestrating these interactions, embodying the fusion of neural and symbolic systems.\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Unknown parameter: 'quality'.\", 'type': 'invalid_request_error', 'param': 'quality', 'code': 'unknown_parameter'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mchain_four\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marticle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43marticle\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages/langchain_core/runnables/base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2499\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2500\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2503\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2504\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2505\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages/langchain_core/runnables/base.py:3963\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3961\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this runnable synchronously.\"\"\"\u001b[39;00m\n\u001b[1;32m   3962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 3963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3964\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3965\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3966\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3967\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3970\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3971\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3972\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3973\u001b[0m     )\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages/langchain_core/runnables/base.py:1626\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1623\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(var_child_runnable_config\u001b[38;5;241m.\u001b[39mset, child_config)\n\u001b[1;32m   1624\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1625\u001b[0m         Output,\n\u001b[0;32m-> 1626\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1629\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1630\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1634\u001b[0m     )\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1636\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages/langchain_core/runnables/config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages/langchain_core/runnables/base.py:3837\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3835\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m   3836\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3837\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3838\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   3839\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3840\u001b[0m \u001b[38;5;66;03m# If the output is a runnable, invoke it\u001b[39;00m\n\u001b[1;32m   3841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages/langchain_core/runnables/config.py:347\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    346\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[87], line 7\u001b[0m, in \u001b[0;36mgenerate_and_display_image\u001b[0;34m(image_prompt)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_and_display_image\u001b[39m(image_prompt):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(image_prompt)\n\u001b[0;32m----> 7\u001b[0m     image_url \u001b[38;5;241m=\u001b[39m \u001b[43mDallEAPIWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage_prompt\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     image_data \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mimread(image_url)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# And update the display code to:\u001b[39;00m\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages/langchain_community/utilities/dalle_image_generator.py:150\u001b[0m, in \u001b[0;36mDallEAPIWrapper.run\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run query through OpenAI and parse result.\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[0;32m--> 150\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     image_urls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseparator\u001b[38;5;241m.\u001b[39mjoin([item\u001b[38;5;241m.\u001b[39murl \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mdata])\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages/openai/resources/images.py:264\u001b[0m, in \u001b[0;36mImages.generate\u001b[0;34m(self, prompt, model, n, quality, response_format, size, style, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    222\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ImagesResponse:\n\u001b[1;32m    223\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    Creates an image given a prompt.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/images/generations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquality\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstyle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimage_generate_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageGenerateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mImagesResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages/openai/_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1277\u001b[0m     )\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Applications/miniconda3/envs/crew_uv/lib/python3.10/site-packages/openai/_base_client.py:1059\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1058\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1062\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1063\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1068\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Unknown parameter: 'quality'.\", 'type': 'invalid_request_error', 'param': 'quality', 'code': 'unknown_parameter'}}"
     ]
    }
   ],
   "source": [
    "chain_four.invoke({\"article\":article})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccf41bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crew_uv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
