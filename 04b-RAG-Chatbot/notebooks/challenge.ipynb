{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bac8b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fitz gave me an error\n",
    "#!pip install --force-reinstall PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c902cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import fitz  # PyMuPDF\n",
    "from io import BytesIO\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3722401a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key initialized: sk-proj-FP...\n"
     ]
    }
   ],
   "source": [
    "###Init clients\n",
    "\"\"\"\n",
    "Initialize OpenAI API and Langsmith\n",
    "\"\"\"\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "print(f\"OpenAI API key initialized: {openai.api_key[0:10]}...\")\n",
    "\n",
    "# Create OpenAI embedding function\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    openai.api_key,\n",
    "    model_name=\"text-embedding-3-small\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e5beb",
   "metadata": {},
   "source": [
    "### Load and split document\n",
    "#### I'll use product manual about Samsung s25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8g4a1y5au0h",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Modulo 1\n",
    "def read_pdf_from_url(url):\n",
    "    \"\"\"\n",
    "    Read PDF from URL and extract raw text using PyMuPDF.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL of the PDF file\n",
    "        \n",
    "    Returns:\n",
    "        str: Extracted text from the PDF\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Download PDF from URL\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Open PDF from bytes\n",
    "        pdf_bytes = BytesIO(response.content)\n",
    "        pdf_document = fitz.open(stream=pdf_bytes, filetype=\"pdf\")\n",
    "        \n",
    "        # Extract text from all pages\n",
    "        text = \"\"\n",
    "        for page_num in range(pdf_document.page_count):\n",
    "            page = pdf_document[page_num]\n",
    "            text += page.get_text()\n",
    "        \n",
    "        pdf_document.close()\n",
    "        return text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF from URL: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0ce1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.samsung.com/ca\n",
      "English (CA). 05/2025. Rev.2.0\n",
      "SM-S931W\n",
      "SM-S936W\n",
      "SM-S937W\n",
      "SM-S938W\n",
      "USER GUIDE\n",
      "2\n",
      "T\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "url = \"https://downloadcenter.samsung.com/content/UM/202505/20250523185456235/SM-S93X_UG_CA_15_Eng_D05_250523.pdf\"\n",
    "text = read_pdf_from_url(url)\n",
    "text_sample = text[:100]\n",
    "print(text_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66e7ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Split text into chunks using RecursiveCharacterTextSplitter.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to split\n",
    "        chunk_size (int): Maximum size of each chunk\n",
    "        chunk_overlap (int): Number of characters to overlap between chunks\n",
    "        \n",
    "    Returns:\n",
    "        list: List of text chunks\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    \n",
    "    # Initialize the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    # Split the text\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fkn2ci64zta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 325\n",
      "First chunk preview: www.samsung.com/ca\n",
      "English (CA). 05/2025. Rev.2.0\n",
      "SM-S931W\n",
      "SM-S936W\n",
      "SM-S937W\n",
      "SM-S938W\n",
      "USER GUIDE\n",
      "2\n",
      "T...\n",
      "Chunk sizes: [995, 998, 992, 995, 951]\n"
     ]
    }
   ],
   "source": [
    "# Example usage with the Samsung manual\n",
    "url = \"https://downloadcenter.samsung.com/content/UM/202505/20250523185456235/SM-S93X_UG_CA_15_Eng_D05_250523.pdf\"\n",
    "text = read_pdf_from_url(url)\n",
    "if text:\n",
    "    chunks = chunk_text(text)\n",
    "    print(f\"Total chunks created: {len(chunks)}\")\n",
    "    print(f\"First chunk preview: {chunks[0][:100]}...\")\n",
    "    print(f\"Chunk sizes: {[len(chunk) for chunk in chunks[:5]]}\")  # Show first 5 chunk sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb6284f",
   "metadata": {},
   "source": [
    "### 2. Generate Embeddings and Store in ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pno9qkyu5v",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_get_vector_db(chunks: List[str], collection_name: str, \n",
    "                    persist_directory: str = \"./chroma_db\") -> chromadb.Collection:\n",
    "    \"\"\"\n",
    "    Create or load a ChromaDB collection with OpenAI embeddings.\n",
    "    \n",
    "    Args:\n",
    "        chunks (List[str]): List of text chunks to embed\n",
    "        collection_name (str): Name of the ChromaDB collection\n",
    "        persist_directory (str): Directory to persist the database\n",
    "        \n",
    "    Returns:\n",
    "        chromadb.Collection: The ChromaDB collection\n",
    "    \"\"\"\n",
    "    # Initialize ChromaDB client with persistence\n",
    "    client = chromadb.PersistentClient(path=persist_directory)\n",
    "    \n",
    "    # Get or create collection\n",
    "    try:\n",
    "        collection = client.get_collection(name=collection_name, embedding_function=openai_ef)\n",
    "        if collection:\n",
    "            print(F\"Collection founded! it has {collection.count()} documents\")\n",
    "            return collection\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Collection not founded; creating it...\")\n",
    "        # Collection doesn't exist, create new one\n",
    "        collection = client.create_collection(\n",
    "            name=collection_name,\n",
    "            embedding_function=openai_ef,\n",
    "            metadata={\"description\": \"Product manual embeddings with OpenAI\"}\n",
    "        )\n",
    "        print(f\"Created new collection '{collection_name}'\")\n",
    "    \n",
    "        if chunks:\n",
    "            # Generate embeddings using OpenAI\n",
    "            print(f\"Embedding {len(chunks)} chunks...\")\n",
    "            \n",
    "            # Prepare documents and metadata\n",
    "            documents = chunks\n",
    "            ids = [f\"chunk_{i}\" for i in range(len(chunks))]\n",
    "            metadatas = [{\"chunk_index\": i, \"chunk_length\": len(chunk)} for i, chunk in enumerate(chunks)]\n",
    "            \n",
    "            # Add documents to collection (ChromaDB will handle embeddings)\n",
    "            collection.add(\n",
    "                documents=documents,\n",
    "                ids=ids,\n",
    "                metadatas=metadatas\n",
    "            )\n",
    "            \n",
    "            print(f\"Successfully embedded {len(chunks)} chunks into ChromaDB\")\n",
    "    \n",
    "        return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a33083be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection founded! it has 325 documents\n"
     ]
    }
   ],
   "source": [
    "samsung_s25_coll = create_or_get_vector_db(chunks=chunks, collection_name=\"samsung-s25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e9fbd",
   "metadata": {},
   "source": [
    "### 3 Basic RAG CHain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "918da9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection founded! it has 325 documents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1. Choose the appropriate shooting mode from the shooting modes list.\\n2. Use the Quick controls icon to adjust settings like colour temperature.\\n3. Use the Shot suggestions feature to get recommendations for the ideal composition.\\n4. If taking a self-portrait, switch to the front camera.\\n5. For low-light conditions, use Night mode without flash for brighter and steadier results.\\n6. Hold your device steady until shooting is complete.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://downloadcenter.samsung.com/content/UM/202505/20250523185456235/SM-S93X_UG_CA_15_Eng_D05_250523.pdf\"\n",
    "collection_name = \"samsung_s25_coll\"\n",
    "question=\"How to take a good picture?\"\n",
    "\n",
    "#Create chunks\n",
    "chunks = chunk_text(read_pdf_from_url(url=url))\n",
    "# Create or get collection\n",
    "collection = create_or_get_vector_db(chunks=chunks, collection_name=collection_name)\n",
    "#Retrieve conxext\n",
    "context = collection.query(query_texts=[question], n_results=3)\n",
    "docs = context['documents'][0]\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "# Create prompt template\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant that answers questions based on the provided context.\n",
    "Use only the information from the context to answer the question.\n",
    "If the answer is not in the context, say \"I don't have enough information to answer this question.\"\n",
    "Context:\n",
    "{context}\n",
    "           \n",
    "Question: {question}\n",
    "           \n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "rag_chain = (\n",
    "    RunnableLambda(lambda x: {\n",
    "        \"context\": \"\\n\\n\".join(docs),\n",
    "        \"question\": question\n",
    "    })\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e84c30b",
   "metadata": {},
   "source": [
    "### Q&A Chatbot on a python library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b7acc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection not founded; creating it...\n",
      "Created new collection 'request'\n",
      "Embedding 242 chunks...\n",
      "Successfully embedded 242 chunks into ChromaDB\n"
     ]
    }
   ],
   "source": [
    "request_url = \"https://app.readthedocs.org/projects/requests/downloads/pdf/latest/\"\n",
    "\n",
    "#1. Read PDF\n",
    "text = read_pdf_from_url(url=request_url)\n",
    "#2. create chunks\n",
    "chunks = chunk_text(text=text)\n",
    "#3. Create collection\n",
    "collection = create_or_get_vector_db(chunks=chunks, collection_name='request')\n",
    "\n",
    "#4. Create simple retriever function\n",
    "def retrieve_context(query: str, n_results: int = 3):\n",
    "    \"\"\"Retrieve relevant context from ChromaDB collection\"\"\"\n",
    "    results = collection.query(query_texts=[query], n_results=n_results)\n",
    "    return results['documents'][0]\n",
    "\n",
    "#5. Create prompt and LLM\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant that answers questions based on the provided context.\n",
    "Use only the information from the context to answer the question.\n",
    "If the answer is not in the context, say \"I don't have enough information to answer this question.\"\n",
    "Context:\n",
    "{context}\n",
    "           \n",
    "Question: {question}\n",
    "           \n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model='gpt-4')\n",
    "\n",
    "# Create RAG chain\n",
    "context_docs = retrieve_context(question)\n",
    "chain = (\n",
    "    RunnableLambda(lambda x: {\n",
    "        \"context\": \"\\n\\n\".join(retrieve_context(question)),\n",
    "        \"question\": question\n",
    "    })\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc535a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a GET request, you can use the following steps:\n",
      "1. Import the requests module in Python: `import requests`\n",
      "2. Use the `requests.get()` function with the URL as the argument: `r = requests.get('https://api.github.com/events')`\n",
      "This will return a Response object which you can use to get all the information you need.\n"
     ]
    }
   ],
   "source": [
    "# Test the RAG chain\n",
    "question = 'How do i create a get request?'\n",
    "response = chain.invoke({\"question\": question})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b441b147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crew_uv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
