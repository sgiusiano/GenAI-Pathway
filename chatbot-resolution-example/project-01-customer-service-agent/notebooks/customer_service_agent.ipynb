{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Customer Service Agent with LangChain\n",
    "\n",
    "This notebook implements a multi-component customer service agent using LangChain Expression Language (LCEL), structured outputs with Pydantic, and LangSmith for observability.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Configuration](#setup)\n",
    "2. [Pydantic Models Definition](#models)\n",
    "3. [Component 1: Query Analysis & Classification](#component1)\n",
    "4. [Component 2: Dynamic Response Generation](#component2)\n",
    "5. [Component 3: Conversation Summarization](#component3)\n",
    "6. [Complete Chain with LCEL](#chain)\n",
    "7. [Testing with Sample Queries](#testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration <a id='setup'></a>\n",
    "\n",
    "First, let's install the required dependencies and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Uncomment the following line to install dependencies\n",
    "# !pip install langchain langchain-openai pydantic python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "from typing import Literal, Optional, List, Dict, Any\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "# Environment setup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pydantic Models Definition <a id='models'></a>\n",
    "\n",
    "We'll define structured data models using Pydantic for:\n",
    "- Query analysis and classification\n",
    "- Entity extraction\n",
    "- Conversation summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ExtractedEntities model for capturing key information from queries\n",
    "class ExtractedEntities(BaseModel):\n",
    "    \"\"\"Entities extracted from customer queries\"\"\"\n",
    "    product_name: Optional[str] = Field(\n",
    "        None, \n",
    "        description=\"The specific product mentioned by the user\"\n",
    "    )\n",
    "    order_number: Optional[str] = Field(\n",
    "        None, \n",
    "        description=\"The order number mentioned by the user (e.g., TEC-2024001)\"\n",
    "    )\n",
    "    date: Optional[str] = Field(\n",
    "        None, \n",
    "        description=\"Any date mentioned in the query\"\n",
    "    )\n",
    "\n",
    "# Define the QueryAnalysis model for structured query classification\n",
    "class QueryAnalysis(BaseModel):\n",
    "    \"\"\"Analyzes and classifies a customer query\"\"\"\n",
    "    query_category: Literal[\n",
    "        \"technical_support\", \n",
    "        \"billing\", \n",
    "        \"returns\", \n",
    "        \"product_inquiry\", \n",
    "        \"general_information\"\n",
    "    ] = Field(\n",
    "        description=\"Category of the customer query\"\n",
    "    )\n",
    "    urgency_level: Literal[\"low\", \"medium\", \"high\"] = Field(\n",
    "        description=\"Urgency level of the query based on customer language and needs\"\n",
    "    )\n",
    "    customer_sentiment: Literal[\"positive\", \"neutral\", \"negative\"] = Field(\n",
    "        description=\"Detected customer sentiment from their message\"\n",
    "    )\n",
    "    entities: ExtractedEntities = Field(\n",
    "        description=\"Key entities extracted from the query\"\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Query analysis models defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ConversationSummary model for logging interactions\n",
    "class ConversationSummary(BaseModel):\n",
    "    \"\"\"A structured summary of the customer service interaction\"\"\"\n",
    "\n",
    "    timestamp: str = Field(\n",
    "        description=\"Timestamp of the interaction in ISO format\"\n",
    "    )\n",
    "    customer_id: str = Field(\n",
    "        default=\"auto_generated\", \n",
    "        description=\"Customer identifier\"\n",
    "    )\n",
    "    conversation_summary: str = Field(\n",
    "        description=\"A concise, one-sentence summary of the interaction\"\n",
    "    )\n",
    "    query_category: str = Field(\n",
    "        description=\"Category of the customer query\"\n",
    "    )\n",
    "    customer_sentiment: str = Field(\n",
    "        description=\"Customer sentiment during the interaction\"\n",
    "    )\n",
    "    urgency_level: str = Field(\n",
    "        description=\"Urgency level of the query\"\n",
    "    )\n",
    "    mentioned_products: List[str] = Field(\n",
    "        description=\"List of products mentioned in the conversation\"\n",
    "    )\n",
    "    extracted_information: ExtractedEntities = Field(\n",
    "        description=\"Key entities extracted from the conversation\"\n",
    "    )\n",
    "    resolution_status: Literal[\"resolved\", \"pending\", \"escalated\"] = Field(\n",
    "        description=\"Current status of the query resolution\"\n",
    "    )\n",
    "    actions_taken: List[str] = Field(\n",
    "        description=\"List of actions the agent took or suggested\"\n",
    "    )\n",
    "    follow_up_required: bool = Field(\n",
    "        description=\"Whether follow-up is required for this interaction\"\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Conversation summary model defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Component 1: Query Analysis & Classification <a id='component1'></a>\n",
    "\n",
    "This component analyzes incoming customer queries and extracts structured information.\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    subgraph \"Input\"\n",
    "        A[Raw Query Text]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Query Analyzer\"\n",
    "        B[Analysis Prompt]\n",
    "        C[LLM with Structured Output]\n",
    "        D[Pydantic Validation]\n",
    "    end\n",
    "    \n",
    "    subgraph \"Structured Output\"\n",
    "        E[QueryAnalysis Object]\n",
    "    end\n",
    "    \n",
    "    A --> B\n",
    "    B --> C\n",
    "    C --> D\n",
    "    D --> E\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Large Language Model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1\",\n",
    "    temperature=0.7,  # Balanced between creativity and consistency\n",
    ")\n",
    "\n",
    "# Create structured output versions of the model\n",
    "# This ensures the model returns data in our Pydantic model format\n",
    "llm_analyzer = llm.with_structured_output(QueryAnalysis)\n",
    "llm_summarizer = llm.with_structured_output(ConversationSummary)\n",
    "\n",
    "print(\"‚úÖ LLM models initialized with structured output!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt template for query analysis\n",
    "analysis_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an AI assistant expert in analyzing customer service queries for TechStore Plus.\n",
    "    \n",
    "    TechStore Plus is an e-commerce technology store based in New York, USA.\n",
    "    We sell electronics, provide technical support, handle warranties, offer financing, and accept trade-ins.\n",
    "    \n",
    "    Analyze the customer query and extract the following information:\n",
    "    1. Query category (technical_support, billing, returns, product_inquiry, general_information)\n",
    "    2. Urgency level (low, medium, high)\n",
    "       - High: Emergency, urgent need, work-critical issues\n",
    "       - Medium: Important but not immediately critical\n",
    "       - Low: General inquiries, non-urgent matters\n",
    "    3. Customer sentiment (positive, neutral, negative)\n",
    "       - Positive: Happy, satisfied, grateful\n",
    "       - Neutral: Matter-of-fact, professional\n",
    "       - Negative: Frustrated, angry, disappointed\n",
    "    4. Key entities like product names, order numbers (format: TEC-YYYYNNN), dates\n",
    "    \n",
    "    Be precise and accurate in your analysis.\"\"\"),\n",
    "    (\"human\", \"{query}\")\n",
    "])\n",
    "\n",
    "# Create the query analyzer by chaining the prompt with the structured LLM\n",
    "query_analyzer = analysis_prompt | llm_analyzer\n",
    "\n",
    "print(\"‚úÖ Query analyzer component created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the query analyzer with a sample query\n",
    "test_query = \"This is an emergency! My order #TEC-2024001 never arrived and I need that laptop for work tomorrow!\"\n",
    "\n",
    "print(\"üß™ Testing Query Analyzer\")\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "\n",
    "analysis_result = query_analyzer.invoke({\"query\": test_query})\n",
    "print(\"Analysis Result:\")\n",
    "print(f\"- Category: {analysis_result.query_category}\")\n",
    "print(f\"- Urgency: {analysis_result.urgency_level}\")\n",
    "print(f\"- Sentiment: {analysis_result.customer_sentiment}\")\n",
    "print(f\"- Entities: {analysis_result.entities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Component 2: Dynamic Response Generation <a id='component2'></a>\n",
    "\n",
    "This component generates context-aware responses based on the query analysis.\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[Query Analysis Result]\n",
    "    B{Route by Category}\n",
    "    \n",
    "    C[Technical Support Prompt]\n",
    "    D[Billing Prompt]\n",
    "    E[Returns Prompt]\n",
    "    F[Product Inquiry Prompt]\n",
    "    G[General Info Prompt]\n",
    "    \n",
    "    H[LLM Generation]\n",
    "    I[Personalized Response]\n",
    "    \n",
    "    A --> B\n",
    "    B -->|technical_support| C\n",
    "    B -->|billing| D\n",
    "    B -->|returns| E\n",
    "    B -->|product_inquiry| F\n",
    "    B -->|general_information| G\n",
    "    \n",
    "    C --> H\n",
    "    D --> H\n",
    "    E --> H\n",
    "    F --> H\n",
    "    G --> H\n",
    "    \n",
    "    H --> I\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define specialized prompts for each query category\n",
    "\n",
    "# Technical Support Prompt - Empathetic and solution-focused\n",
    "technical_support_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an empathetic technical support agent for TechStore Plus.\n",
    "    \n",
    "    Customer Analysis:\n",
    "    - Sentiment: {customer_sentiment}\n",
    "    - Urgency Level: {urgency_level}\n",
    "    - Product Mentioned: {product_name}\n",
    "    \n",
    "    Guidelines:\n",
    "    - Be especially empathetic if the customer is frustrated\n",
    "    - Provide clear, step-by-step troubleshooting instructions\n",
    "    - Acknowledge their frustration and urgency\n",
    "    - Offer immediate solutions or escalation paths\n",
    "    - Keep responses concise but thorough\"\"\"),\n",
    "    (\"human\", \"{original_query}\")\n",
    "])\n",
    "\n",
    "# Billing Prompt - Professional and precise\n",
    "billing_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a professional billing agent for TechStore Plus.\n",
    "    \n",
    "    Customer Analysis:\n",
    "    - Sentiment: {customer_sentiment}\n",
    "    - Order Number: {order_number}\n",
    "    - Date Mentioned: {date}\n",
    "    \n",
    "    Guidelines:\n",
    "    - Be professional and accurate with billing information\n",
    "    - Reference specific order numbers when mentioned\n",
    "    - Explain billing policies clearly\n",
    "    - Offer to email receipts or documentation\n",
    "    - For urgent matters, prioritize quick resolution\"\"\"),\n",
    "    (\"human\", \"{original_query}\")\n",
    "])\n",
    "\n",
    "# Returns Prompt - Understanding and clear about policies\n",
    "returns_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a understanding returns specialist for TechStore Plus.\n",
    "    \n",
    "    Customer Analysis:\n",
    "    - Sentiment: {customer_sentiment}\n",
    "    - Product: {product_name}\n",
    "    - Order Number: {order_number}\n",
    "    \n",
    "    Return Policy:\n",
    "    - 30-day return window with original receipt\n",
    "    - Products must be in original condition\n",
    "    - Refunds processed within 5-7 business days\n",
    "    \n",
    "    Guidelines:\n",
    "    - Be understanding of customer concerns\n",
    "    - Clearly explain the return process\n",
    "    - Offer prepaid return labels for defective items\n",
    "    - Mention warranty options if applicable\"\"\"),\n",
    "    (\"human\", \"{original_query}\")\n",
    "])\n",
    "\n",
    "# Product Inquiry Prompt - Enthusiastic and informative\n",
    "product_inquiry_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an enthusiastic product advisor for TechStore Plus.\n",
    "    \n",
    "    Customer Analysis:\n",
    "    - Sentiment: {customer_sentiment}\n",
    "    - Product Inquired: {product_name}\n",
    "    \n",
    "    Guidelines:\n",
    "    - Be enthusiastic and helpful about products\n",
    "    - Provide detailed product information\n",
    "    - Mention availability and shipping times\n",
    "    - Suggest related products or accessories\n",
    "    - Include pricing information when relevant\"\"\"),\n",
    "    (\"human\", \"{original_query}\")\n",
    "])\n",
    "\n",
    "# General Information Prompt - Friendly and comprehensive\n",
    "general_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a friendly customer service agent for TechStore Plus.\n",
    "    \n",
    "    Customer Analysis:\n",
    "    - Sentiment: {customer_sentiment}\n",
    "    \n",
    "    Guidelines:\n",
    "    - Be friendly and professional\n",
    "    - Provide comprehensive information\n",
    "    - Direct customers to appropriate resources\n",
    "    - Maintain a helpful tone throughout\"\"\"),\n",
    "    (\"human\", \"{original_query}\")\n",
    "])\n",
    "\n",
    "print(\"‚úÖ All category-specific prompts created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a routing dictionary to map categories to their respective prompts\n",
    "prompt_router = {\n",
    "    \"technical_support\": technical_support_prompt,\n",
    "    \"billing\": billing_prompt,\n",
    "    \"returns\": returns_prompt,\n",
    "    \"product_inquiry\": product_inquiry_prompt,\n",
    "    \"general_information\": general_prompt\n",
    "}\n",
    "\n",
    "# Define the routing function that selects the appropriate prompt\n",
    "def route_to_prompt(data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Routes the query to the appropriate prompt based on its category.\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary containing 'analysis' and 'original_query'\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with analysis, query, and formatted prompt\n",
    "    \"\"\"\n",
    "    analysis = data[\"analysis\"]\n",
    "    category = analysis.query_category\n",
    "    \n",
    "    # Prepare data for the prompt template\n",
    "    prompt_data = {\n",
    "        \"original_query\": data[\"original_query\"],\n",
    "        \"customer_sentiment\": analysis.customer_sentiment,\n",
    "        \"urgency_level\": analysis.urgency_level,\n",
    "        \"product_name\": analysis.entities.product_name or \"Not specified\",\n",
    "        \"order_number\": analysis.entities.order_number or \"Not specified\",\n",
    "        \"date\": analysis.entities.date or \"Not specified\"\n",
    "    }\n",
    "    \n",
    "    # Select and format the appropriate prompt\n",
    "    selected_prompt = prompt_router.get(category, general_prompt)\n",
    "    formatted_messages = selected_prompt.format_messages(**prompt_data)\n",
    "    \n",
    "    return {\n",
    "        \"analysis\": analysis,\n",
    "        \"original_query\": data[\"original_query\"],\n",
    "        \"prompt_used\": category,\n",
    "        \"messages\": formatted_messages\n",
    "    }\n",
    "\n",
    "# Create the response generator using LCEL\n",
    "response_generator = (\n",
    "    RunnableLambda(route_to_prompt) \n",
    "    | RunnableLambda(lambda x: {\n",
    "        **x,\n",
    "        \"response\": llm.invoke(x[\"messages\"])\n",
    "    })\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Response generator component created with dynamic routing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Component 3: Conversation Summarization & Persistence <a id='component3'></a>\n",
    "\n",
    "This component creates structured summaries of interactions for logging and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conversation_summary(data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Creates a structured summary of the customer service interaction.\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary containing analysis and response information\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with complete conversation summary data\n",
    "    \"\"\"\n",
    "    analysis = data[\"analysis\"]\n",
    "    response = data[\"response\"]\n",
    "    \n",
    "    # Extract mentioned products\n",
    "    mentioned_products = []\n",
    "    if analysis.entities.product_name:\n",
    "        mentioned_products.append(analysis.entities.product_name)\n",
    "    \n",
    "    # Determine resolution status based on urgency and sentiment\n",
    "    resolution_status = \"resolved\"  # Default\n",
    "    if analysis.urgency_level == \"high\":\n",
    "        resolution_status = \"escalated\"\n",
    "    elif analysis.customer_sentiment == \"negative\":\n",
    "        resolution_status = \"pending\"\n",
    "    \n",
    "    # Determine if follow-up is required\n",
    "    follow_up_required = (\n",
    "        analysis.urgency_level == \"high\" or \n",
    "        analysis.customer_sentiment == \"negative\"\n",
    "    )\n",
    "    \n",
    "    # Create conversation summary\n",
    "    summary_data = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"customer_id\": \"auto_generated\",\n",
    "        \"conversation_summary\": f\"Customer inquired about {analysis.query_category.replace('_', ' ')} with {analysis.customer_sentiment} sentiment\",\n",
    "        \"query_category\": analysis.query_category,\n",
    "        \"customer_sentiment\": analysis.customer_sentiment,\n",
    "        \"urgency_level\": analysis.urgency_level,\n",
    "        \"mentioned_products\": mentioned_products,\n",
    "        \"extracted_information\": {\n",
    "            \"product_name\": analysis.entities.product_name,\n",
    "            \"order_number\": analysis.entities.order_number,\n",
    "            \"date\": analysis.entities.date\n",
    "        },\n",
    "        \"resolution_status\": resolution_status,\n",
    "        \"actions_taken\": [\n",
    "            f\"Provided {analysis.query_category.replace('_', ' ')} assistance\",\n",
    "            \"Analyzed customer query and sentiment\",\n",
    "            \"Generated personalized response\"\n",
    "        ],\n",
    "        \"follow_up_required\": follow_up_required,\n",
    "        \"agent_response\": response.content\n",
    "    }\n",
    "    \n",
    "    return summary_data\n",
    "\n",
    "# Create the summary generation prompt\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Generate a structured summary of this customer service interaction.\n",
    "    \n",
    "    Conversation data:\n",
    "    {conversation_data}\n",
    "    \n",
    "    Create a complete and accurate ConversationSummary.\"\"\"),\n",
    "    (\"human\", \"Please generate the conversation summary.\")\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Conversation summarization component created!\")\n",
    "\n",
    "summary_generator = summary_prompt | llm_summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Complete Chain with LCEL <a id='chain'></a>\n",
    "\n",
    "Now we'll combine all components into a single chain using LangChain Expression Language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the complete chain using LCEL\n",
    "complete_chain = (\n",
    "    # Step 1: Analyze the query\n",
    "    RunnablePassthrough.assign(\n",
    "        analysis=lambda x: query_analyzer.invoke({\"query\": x[\"query\"]})\n",
    "    )\n",
    "    # Step 2: Prepare data for response generation\n",
    "    | RunnableLambda(lambda x: {\n",
    "        \"original_query\": x[\"query\"],\n",
    "        \"analysis\": x[\"analysis\"]\n",
    "    })\n",
    "    # Step 3: Generate response based on analysis\n",
    "    | response_generator\n",
    "    # Step 4: Create conversation summary\n",
    "    | RunnableLambda(lambda x: {\n",
    "        **x,\n",
    "        \"summary_data\": create_conversation_summary(x)\n",
    "    })\n",
    "    # Step 5: Generate final structured summary\n",
    "    | RunnableLambda(lambda x: {\n",
    "        \"response\": x[\"response\"].content,\n",
    "        \"summary\": summary_generator.invoke({\n",
    "            \"conversation_data\": json.dumps(x[\"summary_data\"], indent=2)\n",
    "        })\n",
    "    })\n",
    ")\n",
    "\n",
    "# Helper function to process customer queries\n",
    "def process_customer_query(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Process a customer query through the complete chain.\n",
    "    \n",
    "    Args:\n",
    "        query: The customer's query string\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing the response and conversation summary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = complete_chain.invoke({\"query\": query})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing query: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Complete LCEL chain created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing with Sample Queries <a id='testing'></a>\n",
    "\n",
    "Let's test our complete chain with the suggested test queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test queries as specified in the requirements\n",
    "test_queries = [\n",
    "    {\n",
    "        \"name\": \"Neutral-Informative\",\n",
    "        \"query\": \"Hello, I'd like to know if you have the new iPhone 15 in stock and how much shipping costs to Chicago\",\n",
    "        \"expected_category\": \"product_inquiry\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Urgent-Negative\",\n",
    "        \"query\": \"This is an emergency! My order #TEC-2024001 never arrived and I need that laptop for work tomorrow!\",\n",
    "        \"expected_category\": \"billing\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Satisfied-Positive\",\n",
    "        \"query\": \"Thank you so much for the excellent service with my previous purchase, I want to buy gaming headphones\",\n",
    "        \"expected_category\": \"product_inquiry\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Frustrated-Technical\",\n",
    "        \"query\": \"I can't configure the router I bought last week, I've tried everything and it doesn't work\",\n",
    "        \"expected_category\": \"technical_support\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Formal-Billing\",\n",
    "        \"query\": \"Good morning, I need the receipt for my purchase from December 15th, order #TEC-2023089\",\n",
    "        \"expected_category\": \"billing\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Warranty-Query\",\n",
    "        \"query\": \"I bought a tablet 8 months ago and now it won't turn on, how do I use the warranty?\",\n",
    "        \"expected_category\": \"returns\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üß™ Ready to test {len(test_queries)} sample queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all test queries and collect results\n",
    "test_results = []\n",
    "\n",
    "print(\"=== RUNNING TEST QUERIES ===\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "for i, test in enumerate(test_queries, 1):\n",
    "    print(f\"üìã TEST {i}/{len(test_queries)}: {test['name']}\")\n",
    "    print(f\"üìù Query: {test['query']}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Process the query\n",
    "    result = process_customer_query(test['query'])\n",
    "    \n",
    "    if result:\n",
    "        test_results.append(result)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\nü§ñ AGENT RESPONSE:\")\n",
    "        print(f\"{result['response']}\")\n",
    "        \n",
    "        print(f\"\\nüìä CONVERSATION SUMMARY:\")\n",
    "        summary = result['summary']\n",
    "        print(f\"- Category: {summary.query_category}\")\n",
    "        print(f\"- Sentiment: {summary.customer_sentiment}\")\n",
    "        print(f\"- Urgency: {summary.urgency_level}\")\n",
    "        print(f\"- Status: {summary.resolution_status}\")\n",
    "        print(f\"- Follow-up Required: {summary.follow_up_required}\")\n",
    "        \n",
    "        # Check if category matches expected\n",
    "        if summary.query_category == test['expected_category']:\n",
    "            print(f\"\\n‚úÖ Category classification correct!\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è  Category mismatch: Expected '{test['expected_category']}', got '{summary.query_category}'\")\n",
    "        \n",
    "        # Show extracted information if any\n",
    "        if summary.mentioned_products:\n",
    "            print(f\"\\nüì¶ Products Mentioned: {', '.join(summary.mentioned_products)}\")\n",
    "        \n",
    "        extracted_information = summary.extracted_information\n",
    "        print(f\"\\nüìå EXTRACTED INFORMATION:\")\n",
    "        print(f\"- Product Name: {extracted_information.product_name}\")\n",
    "        print(f\"- Order Number: {extracted_information.order_number}\")\n",
    "        print(f\"- Date: {extracted_information.date}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Failed to process query\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Completed testing {len(test_results)}/{len(test_queries)} queries successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What We've Built:\n",
    "1. **Query Analyzer**: Classifies queries and extracts entities using structured output\n",
    "2. **Dynamic Response Generator**: Routes queries to appropriate prompts based on category\n",
    "3. **Conversation Summarizer**: Creates structured logs of all interactions\n",
    "4. **Complete LCEL Chain**: Integrates all components seamlessly\n",
    "5. **LangSmith Integration**: Enables tracing and debugging\n",
    "\n",
    "### Key Features:\n",
    "- ‚úÖ Structured output with Pydantic models\n",
    "- ‚úÖ Dynamic prompt routing based on query category\n",
    "- ‚úÖ Sentiment and urgency detection\n",
    "- ‚úÖ Entity extraction (products, order numbers, dates)\n",
    "- ‚úÖ Automatic resolution status determination\n",
    "- ‚úÖ Follow-up requirement detection\n",
    "\n",
    "### Resources:\n",
    "- [LangChain Documentation](https://python.langchain.com/)\n",
    "- [LangSmith Documentation](https://docs.smith.langchain.com/)\n",
    "- [LCEL Guide](https://python.langchain.com/docs/expression_language/)\n",
    "- [Pydantic Documentation](https://docs.pydantic.dev/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://python.langchain.com/docs/concepts/lcel\n",
    "- https://www.pinecone.io/learn/series/langchain/langchain-expression-language\n",
    "- https://python.langchain.com/api_reference/core/runnables.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
