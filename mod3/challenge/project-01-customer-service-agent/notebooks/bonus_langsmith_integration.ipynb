{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangSmith Integration (Bonus) <a id='langsmith'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Testing with Sample Queries <a id='testing'></a>\n",
    "\n",
    "Let's test our complete chain with the suggested test queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test queries as specified in the requirements\n",
    "test_queries = [\n",
    "    {\n",
    "        \"name\": \"Neutral-Informative\",\n",
    "        \"query\": \"Hello, I'd like to know if you have the new iPhone 15 in stock and how much shipping costs to Chicago\",\n",
    "        \"expected_category\": \"product_inquiry\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Urgent-Negative\",\n",
    "        \"query\": \"This is an emergency! My order #TEC-2024001 never arrived and I need that laptop for work tomorrow!\",\n",
    "        \"expected_category\": \"billing\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Satisfied-Positive\",\n",
    "        \"query\": \"Thank you so much for the excellent service with my previous purchase, I want to buy gaming headphones\",\n",
    "        \"expected_category\": \"product_inquiry\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Frustrated-Technical\",\n",
    "        \"query\": \"I can't configure the router I bought last week, I've tried everything and it doesn't work\",\n",
    "        \"expected_category\": \"technical_support\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Formal-Billing\",\n",
    "        \"query\": \"Good morning, I need the receipt for my purchase from December 15th, order #TEC-2023089\",\n",
    "        \"expected_category\": \"billing\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Warranty-Query\",\n",
    "        \"query\": \"I bought a tablet 8 months ago and now it won't turn on, how do I use the warranty?\",\n",
    "        \"expected_category\": \"returns\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"üß™ Ready to test {len(test_queries)} sample queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "import os\n",
    "import sys\n",
    "from typing import Literal, Optional, List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Get the notebook directory and project root\n",
    "notebook_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in globals() else os.getcwd()\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "\n",
    "# Add project root to Python path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"üìÅ Project root: {project_root}\")\n",
    "\n",
    "# Import CustomerServiceChain\n",
    "from src.chains import CustomerServiceChain\n",
    "\n",
    "print(\"‚úÖ CustomerServiceChain imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LangSmith Dataset\n",
    "\n",
    "Create an evaluation dataset in LangSmith for tracking performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to create evaluation dataset in LangSmith\n",
    "# Note: This requires LangSmith API access\n",
    "\n",
    "def create_langsmith_dataset():\n",
    "    \"\"\"\n",
    "    Creates an evaluation dataset in LangSmith with our test queries.\n",
    "    Uncomment and run if you have LangSmith configured.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from langsmith import Client\n",
    "        \n",
    "        # Initialize LangSmith client\n",
    "        client = Client()\n",
    "        \n",
    "        # Create dataset\n",
    "        dataset_name = \"customer-service-queries-v1\"\n",
    "        dataset = client.create_dataset(\n",
    "            dataset_name=dataset_name,\n",
    "            description=\"Test queries for customer service agent evaluation\"\n",
    "        )\n",
    "        \n",
    "        # Add examples to the dataset\n",
    "        for test in test_queries:\n",
    "            client.create_example(\n",
    "                inputs={\"query\": test[\"query\"]},\n",
    "                outputs={\"expected_category\": test[\"expected_category\"]},\n",
    "                dataset_id=dataset.id\n",
    "            )\n",
    "        \n",
    "        print(f\"‚úÖ Created dataset '{dataset_name}' with {len(test_queries)} examples\")\n",
    "        print(f\"üìä View in LangSmith: https://smith.langchain.com/datasets/{dataset.id}\")\n",
    "        \n",
    "        return dataset\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  LangSmith integration not available: {str(e)}\")\n",
    "        print(\"Make sure you have:\")\n",
    "        print(\"1. LangSmith API key configured\")\n",
    "        print(\"2. langsmith package installed\")\n",
    "        return None\n",
    "\n",
    "# Uncomment to create dataset\n",
    "# dataset = create_langsmith_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about LangSmith tracing\n",
    "print(\"üìä LANGSMITH TRACING INFORMATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Tracing Enabled: {os.environ.get('LANGSMITH_TRACING', 'false')}\")\n",
    "print(f\"Project Name: {os.environ.get('LANGSMITH_PROJECT', 'Not set')}\")\n",
    "print(f\"\\nüîó View traces at: https://smith.langchain.com\")\n",
    "print(\"\\nTo view traces:\")\n",
    "print(\"1. Ensure you have a LangSmith account\")\n",
    "print(\"2. Set your LANGSMITH_API_KEY environment variable\")\n",
    "print(\"3. Run queries and check the LangSmith dashboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Analysis <a id='analysis'></a>\n",
    "\n",
    "Analyze the performance of our chain based on test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_customer_query(query: str) -> Dict[str, Any]:\n",
    "    agent = CustomerServiceChain()\n",
    "    return agent.process_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all test queries and collect results\n",
    "test_results = []\n",
    "\n",
    "print(\"=== RUNNING TEST QUERIES ===\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "for i, test in enumerate(test_queries, 1):\n",
    "    print(f\"üìã TEST {i}/{len(test_queries)}: {test['name']}\")\n",
    "    print(f\"üìù Query: {test['query']}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Process the query\n",
    "    result = process_customer_query(test['query'])\n",
    "    \n",
    "    if result:\n",
    "        test_results.append(result)        \n",
    "        print(f\"\\n‚úÖ Agent Response: {result['response']}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Failed to process query\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Completed testing {len(test_results)}/{len(test_queries)} queries successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance analysis function\n",
    "def analyze_chain_performance(results: List[Dict[str, Any]]):\n",
    "    \"\"\"\n",
    "    Analyzes the performance of the chain based on test results.\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"No results to analyze\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nüìà PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Initialize counters\n",
    "    categories = {}\n",
    "    sentiments = {}\n",
    "    urgencies = {}\n",
    "    statuses = {}\n",
    "    \n",
    "    # Count occurrences\n",
    "    for result in results:\n",
    "        summary = result['summary']\n",
    "        \n",
    "        # Count categories\n",
    "        cat = summary.query_category\n",
    "        categories[cat] = categories.get(cat, 0) + 1\n",
    "        \n",
    "        # Count sentiments\n",
    "        sent = summary.customer_sentiment\n",
    "        sentiments[sent] = sentiments.get(sent, 0) + 1\n",
    "        \n",
    "        # Count urgency levels\n",
    "        urg = summary.urgency_level\n",
    "        urgencies[urg] = urgencies.get(urg, 0) + 1\n",
    "        \n",
    "        # Count resolution statuses\n",
    "        status = summary.resolution_status\n",
    "        statuses[status] = statuses.get(status, 0) + 1\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nüìä Category Distribution:\")\n",
    "    for cat, count in sorted(categories.items()):\n",
    "        percentage = (count / len(results)) * 100\n",
    "        print(f\"  - {cat}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nüòä Sentiment Distribution:\")\n",
    "    for sent, count in sorted(sentiments.items()):\n",
    "        percentage = (count / len(results)) * 100\n",
    "        print(f\"  - {sent}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n‚ö° Urgency Distribution:\")\n",
    "    for urg, count in sorted(urgencies.items()):\n",
    "        percentage = (count / len(results)) * 100\n",
    "        print(f\"  - {urg}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nüìã Resolution Status Distribution:\")\n",
    "    for status, count in sorted(statuses.items()):\n",
    "        percentage = (count / len(results)) * 100\n",
    "        print(f\"  - {status}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Calculate follow-up rate\n",
    "    follow_ups = sum(1 for r in results if r['summary'].follow_up_required)\n",
    "    follow_up_rate = (follow_ups / len(results)) * 100\n",
    "    print(f\"\\nüîÑ Follow-up Required: {follow_ups}/{len(results)} ({follow_up_rate:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Analysis Complete!\")\n",
    "\n",
    "# Run the analysis\n",
    "analyze_chain_performance(test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
